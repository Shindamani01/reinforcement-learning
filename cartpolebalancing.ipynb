{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "HwUlon4ZAyp_",
        "outputId": "b2c52962-670e-46a4-df07-a6ecbf3384f9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unindent does not match any outer indentation level (<tokenize>, line 35)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m35\u001b[0m\n\u001b[0;31m    totals.append(episode_rewards)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python\n",
        "\n",
        "import gym\n",
        "import numpy as np\n",
        "import argparse\n",
        "from agent import AgentBasic, AgentRandom, AgentLearning\n",
        "import stats\n",
        "\n",
        "\n",
        "def environment_info(env):\n",
        "    ''' Prints info about the given environment. '''\n",
        "    print('************** Environment Info **************')\n",
        "    print('Observation space: {}'.format(env.observation_space))\n",
        "    print('Observation space high values: {}'.format(env.observation_space.high))\n",
        "    print('Observation space low values: {}'.format(env.observation_space.low))\n",
        "    print('Action space: {}'.format(env.action_space))\n",
        "    print()\n",
        "\n",
        "\n",
        "def basic_guessing_policy(env, agent):\n",
        "    ''' Execute random guessing policy.'''\n",
        "    totals = []\n",
        "    for episode in range(500):\n",
        "        episode_rewards = 0\n",
        "        obs = env.reset()\n",
        "        # env.render()\n",
        "        for step in range(1000):  # 1000 steps max unless failure\n",
        "            action = agent.act(obs)\n",
        "            obs, reward, done, info = env.step(action)\n",
        "            episode_rewards += reward\n",
        "            # env.render()\n",
        "            if done:\n",
        "                # Terminal state reached, reset environment\n",
        "                break\n",
        "     totals.append(episode_rewards)\n",
        "\n",
        "    print('************** Reward Statistics **************')\n",
        "    print('Average: {}'.format(np.mean(totals)))\n",
        "    print('Standard Deviation: {}'.format(np.std(totals)))\n",
        "    print('Minimum: {}'.format(np.min(totals)))\n",
        "    print('Maximum: {}'.format(np.max(totals)))\n",
        "\n",
        "\n",
        "def random_guessing_policy(env, agent):\n",
        "    ''' Execute random guessing policy. '''\n",
        "    totals = []\n",
        "    for episode in range(500):\n",
        "        episode_rewards = 0\n",
        "        obs = env.reset()\n",
        "        # env.render()\n",
        "        for step in range(1000):  # 1000 steps max\n",
        "            action = agent.act()\n",
        "            obs, reward, done, info = env.step(action)\n",
        "            episode_rewards += reward\n",
        "            # env.render()\n",
        "            if done:\n",
        "                # Terminal state reached, reset environment\n",
        "                break\n",
        "        totals.append(episode_rewards)\n",
        "\n",
        "    print('Average: {}'.format(np.mean(totals)))\n",
        "    print('Standard Deviation: {}'.format(np.std(totals)))\n",
        "    print('Minimum: {}'.format(np.min(totals)))\n",
        "    print('Maximum: {}'.format(np.max(totals)))\n",
        "\n",
        "\n",
        "def q_learning(env, agent):\n",
        "    '''\n",
        "    Implement Q-learning policy.\n",
        "\n",
        "    Args:\n",
        "        env: Gym enviroment object.\n",
        "        agent: Learning agent.\n",
        "    Returns:\n",
        "        Rewards for training/testing and epsilon/alpha value history.\n",
        "    '''\n",
        "    # Start out with Q-table set to zero.\n",
        "    # Agent initially doesn't know how many states there are...\n",
        "    # so if a new state is found, then add a new column/row to Q-table\n",
        "    valid_actions = [0, 1]\n",
        "    tolerance = 0.001\n",
        "    training = True\n",
        "    training_totals = []\n",
        "    testing_totals = []\n",
        "    history = {'epsilon': [], 'alpha': []}\n",
        "    for episode in range(800):  # 688 testing trials\n",
        "        episode_rewards = 0\n",
        "        obs = env.reset()\n",
        "        # If epsilon is less than tolerance, testing begins\n",
        "        if agent.epsilon < tolerance:\n",
        "            agent.alpha = 0\n",
        "            agent.epsilon = 0\n",
        "            training = False\n",
        "        # Decay epsilon as training goes on\n",
        "        agent.epsilon = agent.epsilon * 0.99  # 99% of epsilon value\n",
        "        for step in range(200):        # 200 steps max\n",
        "            state = agent.create_state(obs)           # Get state\n",
        "            agent.create_Q(state, valid_actions)      # Create state in Q_table\n",
        "            action = agent.choose_action(state)         # Choose action\n",
        "            obs, reward, done, info = env.step(action)  # Do action\n",
        "            episode_rewards += reward                   # Receive reward\n",
        "            # Skip learning for first step\n",
        "            if step != 0:\n",
        "                # Update Q-table\n",
        "                agent.learn(state, action, prev_reward, prev_state, prev_action)\n",
        "            prev_state = state\n",
        "            prev_action = action\n",
        "            prev_reward = reward\n",
        "            if done:\n",
        "                # Terminal state reached, reset environment\n",
        "                break\n",
        "        if training:\n",
        "            training_totals.append(episode_rewards)\n",
        "            agent.training_trials += 1\n",
        "            history['epsilon'].append(agent.epsilon)\n",
        "            history['alpha'].append(agent.alpha)\n",
        "        else:\n",
        "            testing_totals.append(episode_rewards)\n",
        "            agent.testing_trials += 1\n",
        "            # After 100 testing trials, break. Because of OpenAI's rules for solving env\n",
        "            if agent.testing_trials == 100:\n",
        "                break\n",
        "    return training_totals, testing_totals, history\n",
        "\n",
        "\n",
        "def main():\n",
        "    ''' Execute main program. '''\n",
        "    # Create a cartpole environment\n",
        "    # Observation: [horizontal pos, velocity, angle of pole, angular velocity]\n",
        "    # Rewards: +1 at every step. i.e. goal is to stay alive\n",
        "    env = gym.make('CartPole-v0')\n",
        "    # Set environment seed\n",
        "    env.seed(21)\n",
        "    environment_info(env)\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('-a', '--agent', help='define type of agent you want')\n",
        "    args = parser.parse_args()\n",
        "    # Basic agent enabled\n",
        "    if args.agent == 'basic':\n",
        "        agent = AgentBasic()\n",
        "        basic_guessing_policy(env, agent)\n",
        "    # Random agent enabled\n",
        "    elif args.agent == 'random':\n",
        "        agent = AgentRandom(env.action_space)\n",
        "        random_guessing_policy(env, agent)\n",
        "    # Q-learning agent enabled\n",
        "    elif args.agent == 'q-learning':\n",
        "        agent = AgentLearning(env, alpha=0.9, epsilon=1.0, gamma=0.9)\n",
        "        training_totals, testing_totals, history = q_learning(env, agent)\n",
        "        stats.display_stats(agent, training_totals, testing_totals, history)\n",
        "        stats.save_info(agent, training_totals, testing_totals)\n",
        "        # Check if environment is solved\n",
        "        if np.mean(testing_totals) >= 195.0:\n",
        "            print(\"Environment SOLVED!!!\")\n",
        "        else:\n",
        "            print(\"Environment not solved.\",\n",
        "                  \"Must get average reward of 195.0 or\",\n",
        "                  \"greater for 100 consecutive trials.\")\n",
        "    # No argument passed, agent defaults to Basic\n",
        "    else:\n",
        "        agent = AgentBasic()\n",
        "        basic_guessing_policy(env, agent)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    ''' Run main program. '''\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "LUO8N2mJePav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[link text](https://)# New Section"
      ],
      "metadata": {
        "id": "hj91UVR3XN5t"
      }
    }
  ]
}